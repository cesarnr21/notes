# Machine Learning and Artificial Intelligence

**References**
* Hands on Machine Learning with Scikit-Learn, Keras & TensorFlow: <https://www.knowledgeisle.com/wp-content/uploads/2019/12/2-Aur%C3%A9lien-G%C3%A9ron-Hands-On-Machine-Learning-with-Scikit-Learn-Keras-and-Tensorflow_-Concepts-Tools-and-Techniques-to-Build-Intelligent-Systems-O%E2%80%99Reilly-Media-2019.pdf>


### Terminology
Terminology on Google's course: <https://developers.google.com/machine-learning/crash-course/framing/ml-terminology>

- **Label:** the thing we are predicting, a variable, example: `the future price of wheat`. The $\textbf{y variable}$
- **Feature:** it is an input variable. a simple model might use a single feature or millions of features. The $\textbf{x variable}$
    - **Example** is a partical instance of data X: Two kinds:
        - A *labeled example* includes both the features and the label
        - An *unlabeled example* only includes the features and not the label
- A **Model:** is what defines the realtionship between features and the label.
**Training or Learning:** is when you show the model labeled example and enable the model to learn the relationships between features and models
- **Supervised Machine Learning:** a ML system that learns how to combine inputs to produce useful prediction on never seen before data. require labeled data to train.
- **Epoch:** when all the training data is used at once and is defined as the total normal of iterations of all the training data in on cycle for traing the machine learning model.
- **Unsupervised Machine Learning:** this learns patterns in unlabeled data.
- **Supervised Machine Learning:** imitates the way that humans gain knowledge, can be supervised, or unsupervised.
- **Inference:** applying the trained model to unlabeled examples.
- **Regression Models:** predict continuous values such as probability
- **Classification Models:** predict discrete values such as yes or no.
- **Clustering:** just means classifiying into similar groups.
    - **Deep Learning Clustering:** 
- **Generative Adversarial Networks (GANs):** a machine learning approach where there is a Supervised learning problem with two sub-models, a **generator model** trained to generate new examples, and a **discriminator model** that tries to classify the examples as either real (actual real data) or fake (generated by the other model).
    - The two models are trained together until the discriminator is fooled around half the time, meaning that the generator is making plausible examples

## Linear Regression
is a method for finding the straight line or hyperplane that best fits a set of points.

**Loss** is the difference between an actual datapoint and the predicted value from the model. When training a model, the model is trained to reduce loss at every single datapoint


## Google intro to Machine Learning Course

Google Course Intro: <https://developers.google.com/machine-learning/crash-course/>
>note: it uses TensorFlow

# Neural Networks
### Examples

[Building a Layer Two Neural Network From Scratch Using Python](https://betterprogramming.pub/how-to-build-2-layer-neural-network-from-scratch-in-python-4dd44a13ebba)


---


# ECE 5400: Applied Machine Learning

## L1: Intro to AI/ML

**Learning** is any process by which something improves performance from experience  

**Machine Learning** is a set of method that can detect patterns in  data, and then use the uncovered patterns to predict future data.


## L2-L3: Overview of Machine Learning Applications, Types, and Tasks

When to use Machine Learning?
- Human expertise does not exist (navigating on Mars)
- Humans can't explain their expertise (speech recognition)
- Models must be customized (personalized medicine)
- Models are based on huge amounts of data (genomics)

**Artificial Intelligence:** programs with the ability to learn and reason like humans, focused on making machines intelligent.
- Natural Language Processing
- Self-Driving Cars

**Machine Learning:** Subset of Artificial Intelligence, algorithms with the ability to learn without being explicitly programmed

**Neural Networks** try to mimic activity in the brain

**Deep Learning:** subset of Machine Learning in which artificial neural networks adapt and learn from the vast amounts of data. 

On the differences between these concepts, AI is more like the philosophical idea of smart machines. Machine Learning is more like an approach to develop and improve AI.


### Supervised vs Unsupervised Learning
**Supervised Learning:**
- Goal: a program that can perform a task as good as human
- Task: well defined goal
- Experience: training data provided by a human
- Performance: Error/accuracy on the task

**Unsupervised Learning:**
- Goal: to find some kind of structure in the data
- Task: vaguely defined
- There is not experience
- No Performance

**Steps for supervised learning**
1. Training/Learning Step: Training Data and Labels &rarr; ML Algorithm &rarr; Create a **Predictive Model**
2. Testing/Prediction Step: New unseen data &rarr; **Predictive Model** &rarr; Prediction

**Supervised Learning** involves allocating *labeled data* so that the model can create a pattern of function



## L4-L5: Regression vs Classification and Evaluation Metrics
> **Both Regressions and Classification are Supervised Machine Learning**  

### Regression:
- This is the task of approximating a mapping function $f$ from input $x$ to a continuous output $y$: $f(x) = y$
- A continuous output is  a real value, quantities
- A regression problem requires the prediction of a quantity, and the prediction cannot always be perfect.
- To evaluate the performance of a Regression Machine Learning, we use evaluation metrics
	- Mean absolute error
    - mean relative error
    - mean squared error
    - root mean squared error


### Evaluation Metrics for Regression
- **Mean Absolute Error (MAE):** this is the average of all absolute errors.

$$ MAE = \frac{\sum_{i=1}^{n}\left| y_{i} - x_{i}\right|}{n} $$

<p align="center">or</p>

$$ MAE = \frac{\text{sum of the absolute value of all errors}}{\text{number of data points}} $$

- **Mean Absolute Percentage Error (MAPE):** different than MAE because it focuses more on the relative and not the absolute.

$$ MAPE = \frac{1}{n}\sum_{t=1}^{n}|\frac{A_{t}-F_{t}}{A_{t}}| $$

<p align="center">or</p>

$$ MAPE = \frac{1}{\text{number of data points}}\frac{\text{sum of the absolute value of all errors}}{\text{number of errorrs}} $$

- **Mean  Square Error (MSE):** measures the average of the squares of the errors. the average squared difference between the estimated values and the actual value. this is good to get derivatives and to optimize

$$ MSE = \frac{1}{n}\sum_{i=1}^{n}(Y_{i}-\hat{Y_{i}})^2 $$

<p align="center">or</p>

$$ MSE = \frac{\text{sum of the value of all the squares errors}}{\text{number of errorrs}} $$

- **Root Mean  Square Error (RMSE):** this is used more to differentiate an algorithm and better optimize

$$ RMSE = \sqrt{\frac{\sum_{i=1}^{N}(x_{i}-\hat{x}_{i})^2}{N}} $$

<p align="center">or</p>

$$ RMSE = \frac{\text{sum of the value of all the squares errors}}{\text{number of errorrs}} $$

### Classification:
- Predict categorical class labels based on past observations. here the class labels(y) are discrete
- Either Binary (2 categories) or multi-class (multiple) classification problem
- Input either be continuous or discrete
- A **Confusion Matrix** can be used to measure the performance of a classification machine learning algorithms
    $$ accuracy = \frac{correct\_ predictions}{total\_ predictions}$$

### Evaluation Metrics for Classification

Examples of Confusion Matrices

**Dogs vs Cats**

|               | Actual Cat | Actual Dog |
|---------------|------------|------------|
| Predicted Cat | 5          | 2          |
| Predicted Dog | 3          | 3          |

From the table above:
- There 13 Total Animals
- There 8 Cats and 5 Dogs
- Then accuracy of the Model is  
$$ \frac{8}{13} * 100\% = 61\% $$

**COVID Test Results**

|                     |  Actual Positive  |  Actual False  |
|---------------------|-------------------|----------------|
| Positive Prediction | True Positive     | False Positive |
| Negative Prediction | True Negative     | True Negative  |

- **Precision** is the fraction of relevant instances among the retrieved instances
- **Recall/Sensitivity** the fraction of relevant instances that have been retrieved over the total amount of relevant instances

- **F1 Score** considers both the precision and the recall of the test to compute the score. Best value is 1 and worst value is 0. Formula below:
$$F1 = 2 * \frac{precision * recall}{precision + recall} $$


## L6-L9: Linear Regression

The **label** is what you try to predict. the **data** is the **features**
A linear relationship is the simplest way to represent the relationship between data and label. $y(x) = mx + b$

**vector representation:** $$ X * \theta = y $$ 
$X$ is the matrix of features, $\theta$ is the unknowns, and $y$ is the vector of outputs

### Cost Function
$$ J = \frac{sum[(h0(x) - y) ^ 2]}{2m} $$

To improve the model find a theta1 and theta0 that minimizes the error. Squared Error function is the most-widely used cost function

### Gradient Decent


## L10: Linear Regression on Real Datasets


## L11 - L13: Logistic Regression

The difference between Linear and Logistic Regression is that 
The formula for Logistic Regression is $$ h0(x) = \frac{1}{(1 + e ^ [-0^Tx])} $$

**Decision Tree**


## L14: Random Forest
A **Random Forest** is just a bunch of decision trees.





