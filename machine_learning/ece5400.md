
Textbook: [Hands-On Machine Leanring with Scikit-Learn, Keras & TensorFlow](https://www.knowledgeisle.com/wp-content/uploads/2019/12/2-Aur%C3%A9lien-G%C3%A9ron-Hands-On-Machine-Learning-with-Scikit-Learn-Keras-and-Tensorflow_-Concepts-Tools-and-Techniques-to-Build-Intelligent-Systems-O%E2%80%99Reilly-Media-2019.pdf)

fast.ai: <https://www.fast.ai/>

# ECE 5400: Applied Machine Learning

## L1: Intro to AI/ML

**Learning** is any process by which something improves performance from experience  

**Machine Learning** is a set of method that can detect patterns in  data, and then use the uncovered patterns to predict future data.


------------------------------------------------------------------

## L2-L3: Overview of Machine Learning Applications, Types, and Tasks

When to use Machine Learning?
- Human expertise does not exist (navigating on Mars)
- Humans can't explain their expertise (speech recognition)
- Models must be customized (personalized medicine)
- Models are based on huge amounts of data (genomics)

**Artificial Intelligence:** programs with the ability to learn and reason like humans, focused on making machines intelligent.
- Natural Language Processing
- Self-Driving Cars

**Machine Learning:** Subset of Artificial Intelligence, algorithms with the ability to learn without being explicitly programmed

**Neural Networks** try to mimic activity in the brain

**Deep Learning:** subset of Machine Learning in which artificial neural networks adapt and learn from the vast amounts of data. 

On the differences between these concepts, AI is more like the philosophical idea of smart machines. Machine Learning is more like an approach to develop and improve AI.


### Supervised vs Unsupervised Learning
**Supervised Learning:**
- Goal: a program that can perform a task as good as human
- Task: well defined goal
- Experience: training data provided by a human
- Performance: Error/accuracy on the task

**Unsupervised Learning:**
- Goal: to find some kind of structure in the data
- Task: vaguely defined
- There is not experience
- No Performance

**Steps for supervised learning**
1. Training/Learning Step: Training Data and Labels -> ML Algorithm -> Create a **Predictive Model**
2. Testing/Prediction Step: New unseen data -> **Predictive Model** -> Prediction

**Supervised Learning** involves allocating *labeled data* so that the model can create a pattern of function


------------------------------------------------------------------

## L4-L5: Regression vs Classification and Evaluation Metrics
> **Both Regressions and Classification are Supervised Machine Learning**  

### Regression:
- This is the task of approximating a mapping function(f) from input(x) to a continuous output(y):
`f(x) = y`
- A continuous output is  a real value, quantities
- A regression problem requires the prediction of a quantity, and the prediction cannot always be perfect.
- To evaluate the performance of a Regression Machine Learning, we use evaluation metrics
	- `Mean absolute error, mean relative error, mean squared error, root mean squared error`


### Evaluation Metrics for Regression
> note: fix all the formulas below

- **Mean Absolute Error (MAE):** this is the average of all absolute errors. `MAE = (sum of the absolute value of all errors)/number of errors`

- **Mean Absolute Percentage Error (MAPE):** different than MAE because it focuses more on the relative and not the absolute. `MAPE = [(sum of the absolute value of all errors)/number of errors]`

- **Mean  Square Error (MSE):** measures the average of the squares of the errors. the average squared difference between the estimated values and the actual value. this is good to get derivatives and to optimize `MSE = [( sum of the value of all the squares errors)/number of errors]`

- **Root Mean  Square Error (RMSE):** this is used more to differentiate an algorithm and better optimize `RMSE = [( sum of the value of all the squares errors)/number of errors]`


### Classification:
- Predict categorical class labels based on past observations. here the class labels(y) are discrete
- Either Binary (2 categories) or multi-class (multiple) classification problem
- Input either be continuous or discrete
- A **Confusion Matrix** can be used to measure the performance of a classification machine learning algorithms
	- `accuracy = correct predictions / total predictions`

### Evaluation Metrics for Classification

Examples of Confusion Matrices

**Dogs vs Cats**

|               | Actual Cat | Actual Dog |
|---------------|------------|------------|
| Predicted Cat | 5          | 2          |
| Predicted Dog | 3          | 3          |

From the table above:
- There 13 Total Animals
- There 8 Cats and 5 Dogs
- Then accuracy of the Model is `(8 / 13) * 100% = 61%`

**COVID Test Results**

|                     |  Actual Positive  |  Actual False  |
|---------------------|-------------------|----------------|
| Positive Prediction | True Positive     | False Positive |
| Negative Prediction | True Negative     | True Negative  |

- **Precision** is the fraction of relevant instances among the retrieved instances
- **Recall/Sensitivity** the fraction of relevant instances that have been retrieved over the total amount of relevant instances

- **F1 Score** considers both the precision and the recall of the test to compute the score. Best value is 1 and worst value is 0. Formula -> `F1 = 2 * [(precision * recall)/(precision + recall)]`

------------------------------------------------------------------

## L6-L9: Linear Regression

The **label** is what you try to predict. the **data** is the **features**
A linear relationship is the simplest way to represent the relationship between data and label. `y(x) = mx + b`

**vector representation:** `Xtheta = y` X is the matrix of features, theta is the unknowns, and y is the vector of outputs

### Cost Function
`J = sum[(h0(x) - y) ^ 2] / 2m`

To improve the model find a theta1 and theta0 that minimizes the error. Squared Error function is the most-widely used cost function

### Gradient Decent




-----------------------------------------------------------------

## L10: Linear Regression on Real Datasets


-----------------------------------------------------------------

## L11 - L13: Logistic Regression

The difference between Linear and Logistic Regression is that 
The formula for Logistic Regression is `h0(x) = 1 / (1 + e ^ [-0^Tx])`

**Decision Tree**

-----------------------------------------------------------------

## L14: Random Forest
A **Random Forest** is just a bunch of decision trees.





